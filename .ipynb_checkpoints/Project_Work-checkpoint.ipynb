{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "\n",
    "from pyspark.ml.feature import Bucketizer, StringIndexer, OneHotEncoder, StandardScaler, VectorAssembler\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks = pd.read_csv(\"/dbfs/FileStore/tables/outbreaks.csv\")\n",
    "outbreaks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stats\n",
    "#Null values for ingredients and serotype/genotype has been high\n",
    "outbreaks.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall records in the dataset are 19119 which are very almost close to null values in Ingredient and Serotype,\n",
    "#so, we shouldn't consider these values as it might mislead us, its mentioned below too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "sns.heatmap(outbreaks.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks =outbreaks.rename(index=str, columns={\"Serotype/Genotype\": \"Serotype\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,15))\n",
    "sns.countplot(x='Species', data=outbreaks, order= outbreaks.Species.value_counts().iloc[2:8].index)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "df2 = pd.pivot_table(outbreaks, index='State', values='Illnesses', aggfunc='count')\n",
    "ax = df2.plot(kind='bar', color='steelblue',figsize=(25,10))\n",
    "plt.title('Foodborne Illnesses Cases By Year')\n",
    "plt.ylabel('Illiness Cases')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.Food.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.drop(['Ingredient', 'Serotype', 'Species', 'Status', 'Fatalities'], axis=1, inplace=True)\n",
    "outbreaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "sns.heatmap(outbreaks.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Null values in location\n",
    "outbreaks.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking count of values in dataset\n",
    "outbreaks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How illnesses are distributed over dataset\n",
    "plt.cla()\n",
    "sns.distplot(outbreaks.Illnesses, bins=10, color='red')\n",
    "plt.title('Distribution of Illnesses in Traning Set')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of FoodBorne Illnesses by State\n",
    "plt.cla()\n",
    "df2 = pd.pivot_table(outbreaks, index='State', values='Illnesses', aggfunc='sum')\n",
    "ax = df2.plot(kind='bar', color='steelblue',figsize=(25,10))\n",
    "plt.title('Foodborne Illnesses Cases By State')\n",
    "plt.ylabel('Illiness Cases')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of FoodBorne Illnesses by Year\n",
    "plt.cla()\n",
    "df2 = pd.pivot_table(outbreaks, index='Year', values='Illnesses', aggfunc='sum')\n",
    "ax = df2.plot(kind='bar', color='steelblue',figsize=(25,10))\n",
    "plt.title('Foodborne Illnesses Cases By Year')\n",
    "plt.ylabel('Illness Cases')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of illness by Months\n",
    "plt.cla()\n",
    "df2 = pd.pivot_table(outbreaks, index='Month', values='Illnesses', aggfunc='mean')\n",
    "ax = df2.plot(kind='bar', color='steelblue',figsize=(25,10))\n",
    "plt.title('Foodborne Illnesses Cases By Month')\n",
    "plt.ylabel('Illiness Cases')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking top food items\n",
    "outbreaks.Food.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling null values of food column with \"Unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.Food.fillna(\"Unspecified\", inplace=True)\n",
    "outbreaks.Location.fillna(\"Unknown\", inplace=True)\n",
    "outbreaks.Location.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Hospitalizations Null value with 0\n",
    "outbreaks.Hospitalizations.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Normalized Column for Hospitalizations/Illnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks['normalized_hospitalizations'] = outbreaks.apply(lambda row: round((row.Hospitalizations/row.Illnesses)*100), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How Normalized Hospitalizations are distributed over dataset\n",
    "plt.cla()\n",
    "sns.distplot(outbreaks.normalized_hospitalizations, bins=10, color='red')\n",
    "plt.title('Distribution of Normalized Hospitalizations')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "sns.distplot(outbreaks.Illnesses, bins=10, color='red')\n",
    "plt.title('Distribution of Illnesses')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "sns.distplot(np.log10(outbreaks.Illnesses), bins=10, color='red')\n",
    "plt.title('Distribution of Illnesses standardized by log scale')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new column log- illness on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks['Illnesses_log'] = np.log(outbreaks.Illnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functionality to manipulate dataframes\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionality for computing features\n",
    "from pyspark.ml import feature\n",
    "# Functionality for regression\n",
    "from pyspark.ml import regression\n",
    "# Funcionality for classification\n",
    "from pyspark.ml import classification\n",
    "# Object for creating sequences of transformations\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(outbreaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = df.randomSplit([0.6, 0.3, 0.1])\n",
    "display(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base Model\n",
    "model1 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['Year'], outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log')  \n",
    "]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = fn.sqrt(fn.avg((fn.col('Illnesses_log') - fn.col('prediction'))**2))\n",
    "model1.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.transform(testing_df).select(rmse).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.transform(testing_df).select((fn.col('Illnesses_log') - fn.col('prediction'))**2, fn.col('Illnesses_log'), fn.col('prediction')).show(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2 - with year, State and Month\n",
    "model2 = Pipeline(stages=[feature.VectorAssembler(inputCols=['Year'],\n",
    "                                        outputCol='features'),\n",
    "                          feature.StringIndexer(inputCol='Month', outputCol='encoded_Month'),\n",
    "                          feature.VectorAssembler(inputCols=['features', 'encoded_Month'], outputCol='semi_final_features'),\n",
    "                          feature.StringIndexer(inputCol='State', outputCol='encoded_State'),\n",
    "                          feature.VectorAssembler(inputCols=['semi_final_features', 'encoded_State'], outputCol='final_features'),\n",
    "                 regression.LinearRegression(featuresCol='final_features', labelCol='Illnesses_log')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.transform(validation_df).select(rmse).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.transform(testing_df).select(rmse).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.transform(testing_df).select((fn.col('Illnesses_log') - fn.col('prediction'))**2, fn.col('Illnesses_log'), fn.col('prediction')).show(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing String Indexer\n",
    "#indexer_model = StringIndexer(inputCol='Month', outputCol=\"{0}_indexed\".format('Month')).fit(training_df)\n",
    "#indexed_df = indexer_model.transform(training_df)\n",
    "#indexed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 \n",
    "#With state, Month only\n",
    "model3 = Pipeline(stages=[feature.StringIndexer(inputCol='Month', outputCol='encoded_Month'),\n",
    "                          feature.VectorAssembler(inputCols=['encoded_Month'], outputCol='semi_final_features'),\n",
    "                          feature.StringIndexer(inputCol='State', outputCol='encoded_State'),\n",
    "                          feature.VectorAssembler(inputCols=['semi_final_features', 'encoded_State'], outputCol='final_features'),\n",
    "                 regression.LinearRegression(labelCol='Illnesses_log', featuresCol='final_features')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3> Model 2 > Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding String Indexer\n",
    "indexer_model = StringIndexer(inputCol='Month', outputCol=\"{0}_indexed\".format('Month')).fit(df)\n",
    "indexed_df = indexer_model.transform(df)\n",
    "indexer_model2 = StringIndexer(inputCol='State', outputCol=\"{0}_indexed\".format('State')).fit(indexed_df)\n",
    "indexed_df = indexer_model2.transform(indexed_df)\n",
    "indexed_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have a new dataframe indexed with states and month\n",
    "indexed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_new= outbreaks.copy()\n",
    "outbreaks_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_new.drop(['Hospitalizations'], axis=1, inplace=True)\n",
    "outbreaks_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_new.Location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_new.Food.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummies for Location Variable\n",
    "outbreaks_new['Location_modified']=outbreaks_new['Location'].str.split(';').str[0]\n",
    "outbreaks_new['Food_modified']=outbreaks_new['Food'].str.split(',').str[0]\n",
    "outbreaks_new['Food_modified_new']=outbreaks_new['Food_modified'].str.split(';').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_new.Food_modified_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(outbreaks_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(outbreaks_new)\n",
    "df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Year\",\"Month\",\"State\", \"Location_modified\", \"Food_modified_new\"]\n",
    "string_indexer_models = []\n",
    "one_hot_encoders = []\n",
    "for col_name in categorical_columns:\n",
    "    # OneHotEncoders map number indices column to column of binary vectors\n",
    "    string_indexer_model = StringIndexer(inputCol=col_name, outputCol=\"{0}_indexed\".format(col_name)).fit(df)\n",
    "    df = string_indexer_model.transform(df)\n",
    "    string_indexer_models.append(string_indexer_model)\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder(inputCol=\"{0}_indexed\".format(col_name), outputCol=\"{0}_encoded\".format(col_name), dropLast=False)\n",
    "    df = one_hot_encoder.transform(df)\n",
    "    \n",
    "    one_hot_encoders.append(one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between all features and Illnesses_log\n",
    "corr_columns = [\"Year\",\"Month_indexed\",\"State_indexed\", \"Location_modified_indexed\", \"Food_modified_new_indexed\", \"Illnesses_log\"]\n",
    "corr_df=df.select(corr_columns).toPandas()\n",
    "plt.cla()\n",
    "sns.heatmap(corr_df.corr(),annot=True)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = df.randomSplit([0.6, 0.3, 0.1])\n",
    "#display(testing_df)\n",
    "testing_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['State_encoded', 'Location_modified_encoded'],outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log',maxIter=5, regParam=0.0, elasticNetParam=0.0)]).fit(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.transform(training_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.transform(testing_df).select((fn.col('Illnesses_log') - fn.col('prediction'))**2, fn.col('Illnesses_log'), fn.col('prediction')).show(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 6 with all the features - Date, Month, State, Food and Location\n",
    "model6 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log',maxIter=5, regParam=0.00, elasticNetParam=0.0)]).fit(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.transform(training_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 6 modification with non encoded by indexed values\n",
    "model7 = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['Month_indexed','Year_indexed','State_indexed', 'Location_modified_indexed', 'Food_modified_new_indexed'],outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log',maxIter=5, regParam=0.0, elasticNetParam=0.0)]).fit(training_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(testing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.transform(training_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking indexes instead of encoding might not be a great idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 5 is the best till now\\\n",
    "import pyspark.ml.tuning as tune\n",
    "grid = tune.ParamGridBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = regression.LinearRegression(labelCol = 'Illnesses_log', featuresCol = 'features', maxIter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.addGrid(reg.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.addGrid(reg.regParam, np.arange(0,.1,.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=reg.getLabelCol(), predictionCol=reg.getPredictionCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "va= feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossPipe = Pipeline(stages=[va,reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = tune.CrossValidator(estimator = crossPipe, estimatorParamMaps = grid, evaluator= evaluator, numFolds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidatorVerbose(CrossValidator):\n",
    "  def _fit(self, dataset):\n",
    "        est = self.getOrDefault(self.estimator)\n",
    "        epm = self.getOrDefault(self.estimatorParamMaps)\n",
    "        numModels = len(epm)\n",
    "\n",
    "        eva = self.getOrDefault(self.evaluator)\n",
    "        metricName = eva.getMetricName()\n",
    "\n",
    "        nFolds = self.getOrDefault(self.numFolds)\n",
    "        seed = self.getOrDefault(self.seed)\n",
    "        h = 1.0 / nFolds\n",
    "\n",
    "        randCol = self.uid + \"_rand\"\n",
    "        df = dataset.select(\"*\", rand(seed).alias(randCol))\n",
    "        metrics = [0.0] * numModels\n",
    "\n",
    "        for i in range(nFolds):\n",
    "            foldNum = i + 1\n",
    "            print(\"Comparing models on fold %d\" % foldNum)\n",
    "\n",
    "            validateLB = i * h\n",
    "            validateUB = (i + 1) * h\n",
    "            condition = (df[randCol] >= validateLB) & (df[randCol] < validateUB)\n",
    "            validation = df.filter(condition)\n",
    "            train = df.filter(~condition)\n",
    "\n",
    "            for j in range(numModels):\n",
    "                paramMap = epm[j]\n",
    "                model = est.fit(train, paramMap)\n",
    "                # TODO: duplicate evaluator to take extra params from input\n",
    "                metric = eva.evaluate(model.transform(validation, paramMap))\n",
    "                metrics[j] += metric\n",
    "\n",
    "                avgSoFar = metrics[j] / foldNum\n",
    "                print(\"params: %s\\t%s: %f\\tavg: %f\" % (\n",
    "                    {param.name: val for (param, val) in paramMap.items()},\n",
    "                    metricName, metric, avgSoFar))\n",
    "                list1.append([{param.name: val for (param, val) in paramMap.items()},metric,avgSoFar])\n",
    "              # paramsList.append([[{param.name: val for (param, val) in paramMap.items()},metricName,metric,avgSoFar]])\n",
    "\n",
    "        if eva.isLargerBetter():\n",
    "            bestIndex = np.argmax(metrics)\n",
    "        else:\n",
    "            bestIndex = np.argmin(metrics)\n",
    "\n",
    "        bestParams = epm[bestIndex]\n",
    "        bestModel = est.fit(dataset, bestParams)\n",
    "        avgMetrics = [m / nFolds for m in metrics]\n",
    "        bestAvg = avgMetrics[bestIndex]\n",
    "        print(\"Best model:\\nparams: %s\\t%s: %f\" % (\n",
    "            {param.name: val for (param, val) in bestParams.items()},\n",
    "            metricName, bestAvg))\n",
    "\n",
    "        return self._copyValues(CrossValidatorModel(bestModel, avgMetrics))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvVer = CrossValidatorVerbose(estimator = crossPipe, estimatorParamMaps = grid, evaluator= evaluator, numFolds = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = df.randomSplit([0.7,0.3],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvVer.fit(training).transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Parameters automatically\n",
    "list1\n",
    "df_cross_val=pd.DataFrame(list1,columns=['Regularization_Parameters','RMSE','AVG'])\n",
    "df_cross_val.head()\n",
    "df_cross_val['Regularization_Parameters']=df_cross_val['Regularization_Parameters'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross_val['Regularization_Parameters'] = df_cross_val['Regularization_Parameters'].replace({'regParam' : 'regP'}, regex=True)\n",
    "df_cross_val['Regularization_Parameters'] = df_cross_val['Regularization_Parameters'].replace({'elasticNetParam' : 'elNetP'}, regex=True)\n",
    "df_cross_val['Regularization_Parameters'] = df_cross_val['Regularization_Parameters'].replace({'{' : ''}, regex=True)\n",
    "df_cross_val['Regularization_Parameters'] = df_cross_val['Regularization_Parameters'].replace({'}' : ''}, regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cross_val_best=df_cross_val.nsmallest(10, 'RMSE')\n",
    "df_cross_val_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of regularizations with RMSE values\n",
    "plt.figure()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 60)\n",
    "sns.pointplot( y = 'RMSE', x = 'Regularization_Parameters', data = df_cross_val_best, palette='Blues',)\n",
    "plt.xticks(rotation =60)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spark.createDataFrame(df_cross_val_best)\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Value of Regular Param and Elastic Param \n",
    "#params: {regParam': 0.01, 'elasticNetParam': 0.8}\trmse: 0.952868, it will change everytime\n",
    "regParamBest=0.01 \n",
    "elasticNetParamBest=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting these best values in the model 6 taken by us\n",
    "final_regression_model = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded','Location_modified_encoded','Food_modified_new_encoded'],outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log',maxIter=5, regParam=regParamBest, elasticNetParam=elasticNetParamBest)]).fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_regression_model.transform(training).select(rmse).show()\n",
    "#older value was 0.8996500501049035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_result=final_regression_model.transform(test)\n",
    "display(temp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Linear Model\n",
    "plt.cla()\n",
    "plotting_df=temp_result.toPandas()\n",
    "plt.scatter(plotting_df['Illnesses_log'],plotting_df[\"prediction\"])\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModelFit =  cv.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_RMSE_value = evaluator.evaluate(finalModelFit.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_RMSE_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =  finalModelFit.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.select('Illnesses_log', 'prediction').show(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_regression_model.stages[-1].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_regression_model.stages[-1].summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Best Model - Model 6 - final regression model\n",
    "#Finding \"year\" coefficients \n",
    "\n",
    "coefficients_list=final_regression_model.stages[-1].coefficients\n",
    "coefficients_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list=df.toPandas()['Year'].unique()\n",
    "len(year_list)\n",
    "year_coefficients_list= coefficients_list[:18]\n",
    "year_coefficients_list\n",
    "year_coefficients = pd.DataFrame(\n",
    "    {'year': year_list,\n",
    "     'coefficients': year_coefficients_list\n",
    "    })\n",
    "year_coefficients.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting year coefficients\n",
    "plt.cla()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 80)\n",
    "sns.barplot( y = 'coefficients', x = 'year', data = year_coefficients, palette='Blues')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year 2000, Year 2013, Year 2014 are most important factors here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month coefficients\n",
    "month_list=df.toPandas()['Month_indexed'].unique()\n",
    "month_name_list=df.toPandas()['Month'].unique()\n",
    "len(month_list)\n",
    "month_coefficients_list= coefficients_list[18:30]\n",
    "month_coefficients_list\n",
    "month_coefficients = pd.DataFrame(\n",
    "    {'month': month_list,\n",
    "     'coefficients': month_coefficients_list,\n",
    "     'month_name':month_name_list\n",
    "    })\n",
    "month_coefficients.head(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting month coefficients\n",
    "plt.cla()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 80)\n",
    "sns.barplot( y = 'coefficients', x = 'month_name', data = month_coefficients, palette='GnBu_d')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion for Months\n",
    "#Jan seems to be an important one in terms of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For State, coffecients\n",
    "state_list=df.toPandas()['State_indexed'].unique()\n",
    "state_name_list=df.toPandas()['State'].unique()\n",
    "len(state_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_coefficients_list= coefficients_list[30:85]\n",
    "state_coefficients_list\n",
    "state_coefficients = pd.DataFrame(\n",
    "    {'state': state_list,\n",
    "     'coefficients': state_coefficients_list,\n",
    "     'state_name':state_name_list\n",
    "    })\n",
    "state_coefficients_temp=state_coefficients.nlargest(10, 'coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 80)\n",
    "sns.barplot( y = 'coefficients', x = 'state_name', data = state_coefficients_temp, palette='coolwarm')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance of top 10 states in predicting results shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Location, top most features\n",
    "location_list=df.toPandas()['Location_modified_indexed'].unique()\n",
    "location_name_list=df.toPandas()['Location_modified'].unique()\n",
    "len(location_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_coefficients_list= coefficients_list[85:106]\n",
    "location_coefficients_list\n",
    "location_coefficients = pd.DataFrame(\n",
    "    {'location': location_list,\n",
    "     'coefficients': location_coefficients_list,\n",
    "     'location_name':location_name_list\n",
    "    })\n",
    "location_coefficients.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting year coefficients\n",
    "plt.cla()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 100)\n",
    "sns.barplot( y = 'coefficients', x = 'location_name', data = location_coefficients, palette='Blues')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important features found here like food consumed at hospital , or at assisted living facility  or school/college/University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last but not least food\n",
    "food_list=df.toPandas()['Food_modified_new_indexed'].unique()\n",
    "food_name_list=df.toPandas()['Food_modified_new'].unique()\n",
    "len(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_coefficients_list= coefficients_list[106:1055]\n",
    "food_coefficients_list\n",
    "food_coefficients = pd.DataFrame(\n",
    "    {'food': food_list,\n",
    "     'coefficients': food_coefficients_list,\n",
    "     'food_name':food_name_list\n",
    "    })\n",
    "food_coefficients_temp=food_coefficients.nlargest(20, 'coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting year coefficients\n",
    "plt.figure()\n",
    "fig=plt.figure(figsize=(25, 10), dpi= 80)\n",
    "sns.barplot( y = 'coefficients', x = 'food_name', data = food_coefficients_temp, palette='husl')\n",
    "plt.xticks(rotation = 60)\n",
    "plt.tight_layout()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Food Items involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_best = regression.LinearRegression(labelCol = 'Illnesses_log', featuresCol = 'features', maxIter=5, regParam=0.040000000000000001, elasticNetParam=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_prof.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_prof = spark.createDataFrame(outbreaks_new)\n",
    "df_for_prof.show(50)\n",
    "categorical_columns = [\"Year\",\"Month\",\"State\", \"Location_modified\", \"Food_modified_new\"]\n",
    "string_indexer_models = []\n",
    "one_hot_encoders = []\n",
    "training_df_prof, validation_df_prof, testing_df_prof = df_for_prof.randomSplit([0.6, 0.3, 0.1])\n",
    "#display(testing_df)\n",
    "display(testing_df_prof)\n",
    "test_df_prof=testing_df_prof.toPandas()\n",
    "test_df_prof.loc[-1] = [2003, \"August\", \"Utah\", \"Restaurant\", \"Lo Mein\", 4, 3, 0.111, \"Restaurant\", \"Lo Mein\", \"Lo Mein\" ]  # adding a row\n",
    "test_df_prof.index = test_df_prof.index + 1  # shifting index\n",
    "test_df_prof = test_df_prof.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df_prof=spark.createDataFrame(test_df_prof)\n",
    "display(testing_df_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in categorical_columns:\n",
    "    # OneHotEncoders map number indices column to column of binary vectors\n",
    "    string_indexer_model = StringIndexer(inputCol=col_name, outputCol=\"{0}_indexed\".format(col_name)).fit(testing_df_prof)\n",
    "    testing_df_prof = string_indexer_model.transform(testing_df_prof)\n",
    "    string_indexer_models.append(string_indexer_model)\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder(inputCol=\"{0}_indexed\".format(col_name), outputCol=\"{0}_encoded\".format(col_name), dropLast=False)\n",
    "    testing_df_prof = one_hot_encoder.transform(testing_df_prof)\n",
    "    \n",
    "    one_hot_encoders.append(one_hot_encoder)\n",
    "display(testing_df_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model6 = Pipeline(stages=[\n",
    "#  feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features'),\n",
    "#  regression.LinearRegression(featuresCol='features', labelCol='Illnesses_log',maxIter=5, regParam=0.00, elasticNetParam=0.0)]).fit(training_df)#\n",
    "model6.transform(testing_df_prof).select(fn.col('prediction')).show(5)\n",
    "training_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df_prof.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = Pipeline(stages=[\n",
    "  va,\n",
    "  regression.GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",featuresCol='features', labelCol='Illnesses_log',  maxIter=5, regParam=0.0 )]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression\n",
    "model9 = Pipeline(stages=[\n",
    "va,\n",
    "regression.DecisionTreeRegressor(featuresCol='features', labelCol='Illnesses_log')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest regression\n",
    "model10 = Pipeline(stages=[\n",
    "va,\n",
    "regression.RandomForestRegressor(featuresCol='features', labelCol='Illnesses_log')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Regression\n",
    "model11 = Pipeline(stages=[\n",
    "va,\n",
    "regression.GBTRegressor(featuresCol='features', labelCol='Illnesses_log')]).fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.transform(validation_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.transform(testing_df).select(rmse).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best Model has been found with linear regression with set elastic and normal regularization parameters - Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying Time Series Forecasting\n",
    "outbreaks_time_series = outbreaks_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "d = {'January':'01', 'February':'02', 'March':'03', 'April':'04','May':'05', 'June':'06', 'July':'07', 'August':'08', 'Spetember':'09','October':'10', 'November':'11', 'December':'12' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.Month = outbreaks_time_series.Month.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.head(5)\n",
    "outbreaks_time_series.Month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.Year= outbreaks_time_series[\"Year\"].map(str)+ \"-\" + outbreaks_time_series[\"Month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.Year= outbreaks_time_series[\"Year\"]+ \"-\" + \"01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.Year=outbreaks_time_series['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_time_series['Year']=pd.to_datetime(outbreaks_time_series.Year, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_model_df=pd.DataFrame(outbreaks_time_series.groupby('Year')['Illnesses'].sum()).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_model_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "time_series_model_df.plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.xlabel('Year', fontsize=20)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling Average\n",
    "plt.cla()\n",
    "illnesses = time_series_model_df[['Illnesses']]\n",
    "illnesses.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.xlabel('Year', fontsize=20)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_analysis_df=illnesses.rolling(12).mean().reset_index()\n",
    "time_series_analysis_df = time_series_analysis_df[np.isfinite(time_series_analysis_df['Illnesses'])]\n",
    "time_series_analysis_df.reset_index(inplace=True)\n",
    "time_series_analysis_df.drop(['index'], axis=1,inplace=True)\n",
    "time_series_analysis_df.reset_index(inplace=True)\n",
    "time_series_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_analysis_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = spark.createDataFrame(time_series_analysis_df)\n",
    "display(df_time_series)\n",
    "df_time_series.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.types import *\n",
    "df_time_series= df_time_series.select(fn.unix_timestamp(fn.col('Year'), format='yyyy-MM-dd HH:mm:ss.000').alias('date'),'index', 'Illnesses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = df_time_series.where((df_time_series['index'] >= 0) & (df_time_series['index']<150))\n",
    "display(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = df_time_series.where((df_time_series['index'] >= 150) & (df_time_series['index']<=187))\n",
    "display(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training, testing = df_time_series.randomSplit([0.8, 0.2#], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time = Pipeline(stages=[\n",
    "  feature.VectorAssembler(inputCols=['date'], outputCol='features'),\n",
    "  regression.LinearRegression(featuresCol='features', labelCol='Illnesses',maxIter=5, regParam=0.01, elasticNetParam=0.2)  \n",
    "]).fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_time = fn.sqrt(fn.avg((fn.col('Illnesses') - fn.col('prediction'))**2))\n",
    "test_model_time=model_time.transform(testing).select(((fn.col('Illnesses') - fn.col('prediction'))**2),fn.col('Illnesses'), fn.col('prediction'), fn.col('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_time.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time.transform(testing).select(rmse_time).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "a4_dims = (11.7, 8.27)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "g=sns.FacetGrid(data=df_time_series.toPandas(),size=8) #mapping maps in the grids using facetgrid\n",
    "g.map(plt.scatter, 'date', 'Illnesses')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_df=test_model_time.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.plot(test_model_df.date, test_model_df.Illnesses, color='g')\n",
    "plt.plot(test_model_df.date, test_model_df.prediction, color='orange')\n",
    "plt.xlabel('Years 1998-2015')\n",
    "plt.ylabel('Illnesses Occurred')\n",
    "plt.title('Illnesses vs Years - Linear Regression Basic')\n",
    "plt.show()\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Modeling\n",
    "model_time.transform(testing).select(((fn.col('Illnesses') - fn.col('prediction'))**2)).show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(fn.avg(\"Illnesses_log\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(fn.max(\"Illnesses_log\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(fn.min(\"Illnesses_log\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_pandas_df=df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Distribution of Illnesses_log\n",
    "plt.cla()\n",
    "sns.distplot(outbreaks_pandas_df['Illnesses_log'], kde=False, bins=30)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jointplot between Illnesses count and Illnesses_log\n",
    "plt.cla()\n",
    "sns.jointplot(x='Illnesses', y='Illnesses_log', data=outbreaks_pandas_df , kind='kde')\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "print outbreaks_pandas_df[outbreaks_pandas_df.Illnesses_log >=3]['Illnesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "print outbreaks_pandas_df[outbreaks_pandas_df.Illnesses_log >=2].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_pandas_df['Illnesses_impact'] = np.where(outbreaks_pandas_df['Illnesses_log']>=2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks_pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_pipes import pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = spark.createDataFrame(outbreaks_pandas_df)\n",
    "display(df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df2,testing_df2 = df_log.randomSplit([0.8, 0.2], 0)\n",
    "display(training_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class1 = pipe(feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features'),\n",
    "     classification.LogisticRegression(labelCol='Illnesses_impact'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class1_fitted = model_class1.fit(training_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class1_fitted.transform(testing_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_evaluation(model_pipeline, model_fitted, data):\n",
    "  return BinaryClassificationEvaluator(labelCol=model_pipeline.getStages()[-1].getLabelCol(), \n",
    "                                rawPredictionCol=model_pipeline.getStages()[-1].getRawPredictionCol()).\\\n",
    "    evaluate(model_fitted.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1ROC_test=binary_evaluation(model_class1,model_class1_fitted,testing_df2)\n",
    "model1ROC_test\n",
    "#base accuracy 0.7563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1ROC_train=binary_evaluation(model_class1,model_class1_fitted,training_df2)\n",
    "model1ROC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use of feature scaling to see if roc increases\n",
    "model_class2 = pipe(feature.VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'],outputCol='features'),\n",
    "                    feature.StandardScaler(withMean=True),\n",
    "     classification.LogisticRegression(labelCol='Illnesses_impact'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class2_fitted = model_class2.fit(training_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class2_fitted.transform(testing_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2ROC_train=binary_evaluation(model_class2,model_class2_fitted,training_df2)\n",
    "model2ROC_train\n",
    "#Scaling doesn't help much here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2ROC_test=binary_evaluation(model_class2,model_class2_fitted,testing_df2)\n",
    "model2ROC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Regularization and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = classification.LogisticRegression(labelCol='Illnesses_impact', featuresCol = 'features', maxIter=5)\n",
    "lr.getPredictionCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0., 0.2, 0.4, 0.6, 0.8, 1.0]) \\\n",
    "    .addGrid(lr.regParam, [ 0. ,  0.01,  0.02,  0.03,  0.04,  0.05,  0.06,  0.07,  0.08,  0.09]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator2 = BinaryClassificationEvaluator(labelCol=lr.getLabelCol(), rawPredictionCol=lr.getPredictionCol())\n",
    "crossPipe2 = Pipeline(stages=[va,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = tune.CrossValidator(estimator = crossPipe2, estimatorParamMaps = paramGrid, evaluator= evaluator2, numFolds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_class_model_fitted = cv2.fit(training_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3ROC_test=evaluator2.evaluate(final_class_model_fitted.transform(testing_df2))\n",
    "model3ROC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3ROC_train=evaluator2.evaluate(final_class_model_fitted.transform(training_df2))\n",
    "model3ROC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempt\n",
    "training_df3, validation_df3, testing_df3 = df_log.randomSplit([0.6, 0.3, 0.1])\n",
    "display(training_df3)\n",
    "feature_assembler = VectorAssembler(inputCols=['Month_encoded','Year_encoded','State_encoded', 'Location_modified_encoded', 'Food_modified_new_encoded'], outputCol=\"features\")\n",
    "assembled_train_df = feature_assembler.transform(training_df3).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_validation_df = feature_assembler.transform(validation_df3).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_test_df = feature_assembler.transform(testing_df3).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch how we specify the class_weight using the weightCol feature\n",
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Illnesses_impact', maxIter=20, family='binomial')\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Illnesses_impact', metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = log_reg.fit(assembled_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.transform(assembled_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_preds.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_areaUnderROC = evaluator.evaluate(train_preds)\n",
    "train_areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpredlbls = train_preds.select(\"prediction\", \"Illnesses_impact\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpredlbls.limit(500).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predlbls):\n",
    "    counttotal = predlbls.count()\n",
    "    correct = predlbls.filter(col('Illnesses_impact') == col(\"prediction\")).count()\n",
    "    wrong = predlbls.filter(col('Illnesses_impact') != col(\"prediction\")).count()\n",
    "    ratioCorrect = float(correct)/counttotal\n",
    "    print(\"Correct: {0}, Wrong: {1}, Model Accuracy: {2}\".format(correct, wrong, np.round(ratioCorrect, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(trainpredlbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = model.evaluate(assembled_train_df)\n",
    "validation_summary = model.evaluate(assembled_validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy   :', train_summary.accuracy)\n",
    "print('Validation Accuracy :', validation_summary.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary.areaUnderROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_summary.fMeasureByLabel(beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_summary.precisionByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_summary.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our model should at least perform better than the Null Accuracy. Null Accuracy is defined as the accuracy we would have got if we would have blindly predicted the majority class of the training set as the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for Base Model, Null Accuracy\n",
    "train_total = trainpredlbls.count()\n",
    "train_label0count = float(trainpredlbls.filter(col(\"Illnesses_impact\") == 0.0).count())\n",
    "train_label1count = float(trainpredlbls.filter(col(\"Illnesses_impact\") == 1.0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we would have predicted everything to be the majority label then what would have been the accuracy\n",
    "max(train_label0count, train_label1count) / train_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Accuracy\n",
    "test_preds = model.transform(assembled_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_areaUnderROC = evaluator.evaluate(test_preds)\n",
    "test_areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredlbls = test_preds.select(\"prediction\", \"Illnesses_impact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(testpredlbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary = model.evaluate(assembled_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.fMeasureByLabel(beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.precisionByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary.roc.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_pdf = train_summary.roc.toPandas()\n",
    "validation_roc_pdf = validation_summary.roc.toPandas()\n",
    "test_roc_pdf = test_summary.roc.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_roc_pdf['FPR'], train_roc_pdf['TPR'], lw=1, label='Train AUC = %0.2f' % (train_summary.areaUnderROC))\n",
    "plt.plot(validation_roc_pdf['FPR'], validation_roc_pdf['TPR'], lw=1, label='Validation AUC = %0.2f' % (test_summary.areaUnderROC))\n",
    "plt.plot(test_roc_pdf['FPR'], test_roc_pdf['TPR'], lw=1, label='Test AUC = %0.2f' % (validation_summary.areaUnderROC))\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='NULL Accuracy')\n",
    "plt.title('ROC AUC Curve')\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"best\" )\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Project_Work",
  "notebookId": 3230718606882710
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
